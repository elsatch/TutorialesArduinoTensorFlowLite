{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "arduino_tinyml_workshop.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f92-4Hjy7kA8",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
    "# Tiny ML en Arduino\n",
    "## Tutorial de reconocimiento de gestor\n",
    " * Sandeep Mistry - Arduino\n",
    " * Don Coleman - Chariot Solutions\n",
    "\n",
    "Traducción a castellano por César García Saéz de La Hora Maker (http://www.lahoramaker.com) \n",
    " \n",
    "Repositorio original: https://github.com/arduino/ArduinoTensorFlowLiteTutorials/\n",
    "\n",
    "Repositorio traducido: https://github.com/elsatch/TutorialesArduinoTensorFlowLite/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvDA8AK7QOq-",
    "colab_type": "text"
   },
   "source": [
    "## Configurar el entorno Python\n",
    "\n",
    "Esta celda configura las dependencias requeridas para el cuaderno. Ejecútala pulsando el botón a la izquierda."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y2gs-PL4xDkZ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Configurar el entorno\n",
    "!apt-get -qq install xxd\n",
    "!pip install pandas numpy matplotlib\n",
    "!pip install tensorflow==2.0.0-rc1"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lwkeshJk7dg",
    "colab_type": "text"
   },
   "source": [
    "# Cargar los datos\n",
    "\n",
    "1. Abre el panel de la izquierda del Colab pulsando sobre la flecha  __>__\n",
    "2. Selecciona la pestaña Ficheros (files)\n",
    "3. Arrastra los ficheros `saludo.csv` y `pulgarabajo.csv` desde tu ordenador para subirlos dentro de tu proyecto de Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh9yve14gUyD",
    "colab_type": "text"
   },
   "source": [
    "# Mostrar gráficamente los datos (opcional)\n",
    "\n",
    "Vamos a dibujar los datos de los ficheros de entrada en dos gráficos separados, aceleración y giróscopo, ya que cada conjunto de datos tiene distintas unidades y escalas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I65ukChEgyNp",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"saludo.csv\"\n",
    "\n",
    "df = pd.read_csv(\"/content/\" + filename)\n",
    "\n",
    "index = range(1, len(df['aX']) + 1)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "plt.plot(index, df['aX'], 'g.', label='x', linestyle='solid', marker=',')\n",
    "plt.plot(index, df['aY'], 'b.', label='y', linestyle='solid', marker=',')\n",
    "plt.plot(index, df['aZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
    "plt.title(\"Acceleration\")\n",
    "plt.xlabel(\"Sample #\")\n",
    "plt.ylabel(\"Acceleration (G)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(index, df['gX'], 'g.', label='x', linestyle='solid', marker=',')\n",
    "plt.plot(index, df['gY'], 'b.', label='y', linestyle='solid', marker=',')\n",
    "plt.plot(index, df['gZ'], 'r.', label='z', linestyle='solid', marker=',')\n",
    "plt.title(\"Gyroscope\")\n",
    "plt.xlabel(\"Sample #\")\n",
    "plt.ylabel(\"Gyroscope (deg/sec)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSxUeYPNQbOg",
    "colab_type": "text"
   },
   "source": [
    "# Entrenar la red neuronal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxk414PU3oy3",
    "colab_type": "text"
   },
   "source": [
    "## Interpretar y preparar los datos\n",
    "\n",
    "La siguiente celda interpreta los contenidos de los ficheros csv y los transforma a un formato que pueder ser utilizado para entrenar la red neuronal totalmente conectada.\n",
    "\n",
    "Actualiza la lista `GESTURES` con los datos de los distintos gestos que has recogido en formato `.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AGChd1FAk5_j",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
    "\n",
    "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
    "# the same random numbers each time the notebook is run\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# the list of gestures that data is available for\n",
    "GESTURES = [\n",
    "    \"saludo\",\n",
    "    \"pulgarabajo\",\n",
    "]\n",
    "\n",
    "SAMPLES_PER_GESTURE = 119\n",
    "\n",
    "NUM_GESTURES = len(GESTURES)\n",
    "\n",
    "# create a one-hot encoded matrix that is used in the output\n",
    "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# read each csv file and push an input and output\n",
    "for gesture_index in range(NUM_GESTURES):\n",
    "  gesture = GESTURES[gesture_index]\n",
    "  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
    "  \n",
    "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "  \n",
    "  df = pd.read_csv(\"/content/\" + gesture + \".csv\")\n",
    "  \n",
    "  # calculate the number of gesture recordings in the file\n",
    "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
    "  \n",
    "  print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
    "  \n",
    "  for i in range(num_recordings):\n",
    "    tensor = []\n",
    "    for j in range(SAMPLES_PER_GESTURE):\n",
    "      index = i * SAMPLES_PER_GESTURE + j\n",
    "      # normalize the input data, between 0 to 1:\n",
    "      # - acceleration is between: -4 to +4\n",
    "      # - gyroscope is between: -2000 to +2000\n",
    "      tensor += [\n",
    "          (df['aX'][index] + 4) / 8,\n",
    "          (df['aY'][index] + 4) / 8,\n",
    "          (df['aZ'][index] + 4) / 8,\n",
    "          (df['gX'][index] + 2000) / 4000,\n",
    "          (df['gY'][index] + 2000) / 4000,\n",
    "          (df['gZ'][index] + 2000) / 4000\n",
    "      ]\n",
    "\n",
    "    inputs.append(tensor)\n",
    "    outputs.append(output)\n",
    "\n",
    "# convert the list to numpy array\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)\n",
    "\n",
    "print(\"Data set parsing and preparation complete.\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5_61831d5AM",
    "colab_type": "text"
   },
   "source": [
    "## Aleatorizar y dividir las entradas y salidas para el entrenamiento\n",
    "\n",
    "Dividir las entradas y salidas en tres conjuntos de datos: 60% para entrenamiento, 20% para validación, y 20% para pruebas.\n",
    "\n",
    "  - El conjunto de entrenamiento se utiliza para entrenar el modelo\n",
    "  - El conjunto de validación se utilizar para medir lo bien que va entrenándose el modelo durante el entrenamiento\n",
    "  - El conjunto de pruebas se emplean para verificar el modelo después de entreamiento"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QfNEmUZMeIEx",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"Data set randomization and splitting complete.\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9g2n41p24nR",
    "colab_type": "text"
   },
   "source": [
    "## Construir y entrenar el modelo\n",
    "\n",
    "Construimos y entrenamos un modelo de [TensorFlow](https://www.tensorflow.org) utilizando la API de alto nivel [Keras](https://www.tensorflow.org/guide/keras)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kGNFa-lX24Qo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUDPvaJE1wRE",
    "colab_type": "text"
   },
   "source": [
    "## Verificación\n",
    "\n",
    "Dibujamos el rendimiento del modelo frente a la validación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxA0zCOaS35v",
    "colab_type": "text"
   },
   "source": [
    "### Dibujar las pérdidas\n",
    "\n",
    "Dibujamos las pérdidas para detectar cuando deja de mejorar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bvFNHXoQzmcM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# increase the size of the graphs. The default size is (6,4).\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(plt.rcParams[\"figure.figsize\"])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG3m-VpE1zOd",
    "colab_type": "text"
   },
   "source": [
    "### Dibujamos las péridas de nuevo, saltando un poco del principio\n",
    "\n",
    "Vamos a dibujar los mismos gráficos de la celda anterior, pero empezaremos en el índice 100 de forma que podemos ampliar la gráfica una vez que el modelo comience a converger."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c3xT7ue2zovd",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# graph the loss again skipping a bit of the start\n",
    "SKIP = 100\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRjvkFQy2RgS",
    "colab_type": "text"
   },
   "source": [
    "### Dibujamos el error absoluto medio\n",
    "\n",
    "[Error absoluto medio](https://es.wikipedia.org/wiki/Error_absoluto_medio) es otra métrica para medir el rendimiento del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mBjCf1-2zx9C",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# graph of mean absolute error\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guMjtfa42ahM",
    "colab_type": "text"
   },
   "source": [
    "### Ejecutar con datos de prueba\n",
    "Añadimos nuestros datos de prueba en el modelo y dibujamos las predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V3Y0CCWJz2EK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(inputs_test)\n",
    "\n",
    "# print the predictions and the expected ouputs\n",
    "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
    "print(\"actual =\\n\", outputs_test)\n",
    "\n",
    "# Plot the predictions along with to the test data\n",
    "plt.clf()\n",
    "plt.title('Training data predicted vs actual values')\n",
    "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
    "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7DO6xxXVCym",
    "colab_type": "text"
   },
   "source": [
    "# Convertimos el modelo entrenado a Tensor Flow Lite\n",
    "\n",
    "La celda siguiente convierte el modelo al formato TFlite. También se imprime el tamaño del modelo en bytes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Xn1-Rn9Cp_8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)\n",
    "  \n",
    "  "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykccQn7SXrUX",
    "colab_type": "text"
   },
   "source": [
    "## Codificar el modelo en un fichero de cabeceras de Arduino\n",
    "\n",
    "La siguiente celda crea un array de bytes constantes que contiene el modelo TFlite. Lo importaremos como una pestaña con el siguiente programa."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9J33uwpNtAku",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
    "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
    "!echo \"};\"                              >> /content/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
    "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eSkHZaLzMId",
    "colab_type": "text"
   },
   "source": [
    "# Clasificando los datos de la IMU\n",
    "\n",
    "Es hora de volver a las instrucciones del tutorial y ejecutar nuestro nuevo modelo en el Arduino Nano 33 BLE Sense para clasificar los datos del giróscopo y acelerómetro.\n"
   ]
  }
 ]
}